# Text Understanding Papers

## Introduction

## Papers

### Basic
1. **A Neural Attention Model for Abstractive Sentence Summarization**. *EMNLP 2015*. [[PDF](https://arxiv.org/pdf/1509.00685.pdf)]
2. **Teaching Machines to Read and Comprehend**. *NIPS 2015*. [[PDF](https://arxiv.org/pdf/1506.03340.pdf)]
3. **Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context**. *ACL2019*. [[PDF](https://arxiv.org/pdf/1901.02860.pdf )]
4. **Generating Long Sequences with Sparse Transformers**. *OPENAI*. [[PDF](https://arxiv.org/pdf/1904.10509.pdf  )] [[code](https://github.com/openai/sparse_attention)]
